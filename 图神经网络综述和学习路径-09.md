### 背景介绍

![截屏2023-03-12 下午3.54.12](https://p.ipic.vip/olcmxx.png)

![截屏2023-03-12 下午4.01.02](https://p.ipic.vip/u0ut60.png)

图深度学习解决的问题：图表示学习

![截屏2023-03-12 下午4.02.07](https://p.ipic.vip/wxsd1p.png)

![截屏2023-03-12 下午4.03.16](https://p.ipic.vip/m6nc70.png)

![截屏2023-03-12 下午4.04.51](https://p.ipic.vip/t8d3lx.png)

### 综述和学习路径

![截屏2023-03-12 下午4.11.33](https://p.ipic.vip/57o0mj.png)

==https://paperswithcode.com/area/graphs==（‼️）

![截屏2023-03-12 下午4.12.38](https://p.ipic.vip/bimaz7.png)

![截屏2023-03-12 下午4.16.38](https://p.ipic.vip/s1ji0m.png)

### 图深度学习的难点和挑战

![截屏2023-03-12 下午4.19.29](https://p.ipic.vip/nhmeim.png)

https://distill.pub/2021/understanding-gnns

![截屏2023-03-12 下午4.22.02](https://p.ipic.vip/5wbr5a.png)

![截屏2023-03-12 下午4.22.49](https://p.ipic.vip/escyh8.png)

#### 1.邻接矩阵A包含了节点相互连接的所有信息，能否直接将邻接矩阵A输入神经网络中？

- **过拟合**，因为邻接矩阵是n\*n的矩阵，将邻接矩阵传入到神经网络中，第一层有n个神经元，每个神经元是n\*1的向量，如果n很大的时候，可能会存在过拟合情况；
- **无法泛化到新节点**，因为将邻接矩阵传入神经网络中，每个神经元是n\*1的向量，如果新增节点，邻接矩阵变成$(n+1)*(n+1)$,则每个节点需要转化为（n+1)*1的向量，但实际无法实现，所以无法泛化新节点；
- **不具备变换不变性**，由于节点的不同编码，得到的邻接矩阵不同，得到输出结果也会不同，而节点的嵌入表示结果，应该与节点编号顺序无关，所以不能直接使用邻接矩阵输入神经网络中。

![截屏2023-03-12 下午4.25.16](https://p.ipic.vip/3igaz4.png)

节点的嵌入表示结果，应该与节点编号顺序无关。

如果使用邻接矩阵的不同节点编码顺序，得到结果如下：

![截屏2023-03-12 下午4.31.06](https://p.ipic.vip/d0yh0s.png)

![截屏2023-03-12 下午4.30.51](https://p.ipic.vip/75ozp2.png)

![截屏2023-03-12 下午4.31.19](https://p.ipic.vip/1xywmz.png)

![截屏2023-03-12 下午4.33.23](https://p.ipic.vip/3h90xy.png)

![截屏2023-03-12 下午4.33.44](https://p.ipic.vip/d1aaj5.png)

**置换不变性**

![截屏2023-03-12 下午4.40.09](https://p.ipic.vip/0jpxju.png)

#### 2.是否参考已有的神经网络结构？例如：卷积神经网络cnn

没有

- 图中没有固定参考点和滑动窗口；
- 图具有变换不变性；

![截屏2023-03-12 下午4.44.22](https://p.ipic.vip/ipcwbh.png)

### 图卷积神经网络-计算图GCN

![截屏2023-03-12 下午4.45.35](https://p.ipic.vip/7x3cw8.png)

黑色盒子是同一个神经网络，白色盒子是另一个神经网络。

![截屏2023-03-12 下午4.56.24](https://p.ipic.vip/xw3rqv.png)

![截屏2023-03-12 下午4.58.31](https://p.ipic.vip/rxjtbz.png)

同一层的神经网络是相同的（图上的同一个方块是相同的）

![截屏2023-03-12 下午5.00.56](https://p.ipic.vip/rzdvhw.png)

图卷积神经网络层数过多的时候，会导致图过平滑。

当k=6层时，考虑到六度空间理论，就会导致所有节点的计算图都很类似，会导致过平滑。

![截屏2023-03-12 下午5.12.11](https://p.ipic.vip/0e11u3.png)

![截屏2023-03-12 下午5.14.00](https://p.ipic.vip/469et4.png)

![截屏2023-03-12 下午5.14.30](https://p.ipic.vip/ja3rlp.png)

![截屏2023-03-12 下午5.16.38](https://p.ipic.vip/vsurdl.png)

### 思考题

**1.什么是图机器学习？什么是图表示学习？什么是图嵌入？什么是图深度学习？**

图机器学习就是将图进行特征工程，然后用机器学习方法进行分析；

图表示学习是在节点、连接、子图层面进行特征工程，得到特征向量；

图嵌入是将高维空间的图转化为低维连续稠密的向量；

图深度学习是使用深度学习对图进行机器学习；

**2.图神经网络本质上在解决什么问题？**

进行节点预测

**3.图神经网络可以解决哪些图机器学习任务？这些任务都有哪些Benchmark？**

节点分类预测、连接预测等

**4.图神经网络包含哪些研究领域？可以和哪些人工智能研究方向交叉？**

研究领域：推荐系统、搜索引擎、社交网络、生物医药等；

人工智能研究方向：人脸识别、社交网络；

**5.什么是图转换？图匹配？图结构学习？**

图转换定义 **按照某些预定义的转换规则，对一种图形中的某些元素进行替换，从而得到另一种图形的过程**。

图匹配（Graph Matching）是指**在两个或多个图（graph）结构之间，建立节点与节点的对应关系**。

图结构学习是指**为了得到更好的图结构，联合优化训练图结构以及图表征的方法**。

**6.为什么不能把邻接矩阵直接输入到神经网络中？**

- 过拟合
- 无法泛化到新节点
- 不具有变换不变性

**7.为什么不能把图直接输入到卷积神经网络中？**

- 图中不具有固定参考点和滑动窗口
- 图不具备变换不变性

**8.什么是消息传递图神经网络？**

https://github.com/datawhalechina/team-learning-nlp/blob/master/GNN/Markdown%E7%89%88%E6%9C%AC/4-%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md

**消息传递范式是一种聚合邻接节点信息来更新中心节点信息的范式**，它将卷积算子推广到了不规则数据领域，实现了图与神经网络的连接。遵循消息传递范式的图神经网络被称为消息传递图神经网络

**9.如何理解“顺序不变性”和“顺序等变性”？**

顺序不变性：调整顺序对结构不产生影响；

顺序等变性：不依赖图节点的顺序。如果我们以某种方式置换节点，那么由我们的算法计算得到的节点表示也应该以相同的方式置换。