## 图的基本表示

### 图的相关知识点

- 传统数据分析中样本是独立同分布的；图神经网络中数据间、样本间是相互联系的，所以不能使用传统的神经网络方法；

- 图神经网络是端到端的表示学习，可以自动学习图中的信息，不需要人进行干预；

- 节点、连接、子图、图都可以有特征，都可以进行数据挖掘；

### 图的基本表示

- 图的本体设计（取决于目的）
- 图的种类（有向、无向、异质（不同类型的节点/连接的图）、二分（两种节点的图，例如：演员和电影，作者和论文等）、连接带权重）
- 节点连接数（节点：nodes；连接：edges；图：graph) --G(N,E)
- 图的基本表示-邻接矩阵
- 图的基本表示-连接列表和邻接列表
- 图的连通性

### 节点的度

节点的度：节点连接数

无向图的平均度：$\bar{k}=<k>=\frac{1}{N}\sum_{i=1}^{N}k_i=\frac{2E}{N}$

有向图的平均度：$\bar{k}=\frac{E}{N}$

有向图的入度和出度平均值关系：$\bar{k^{in}}=\bar{k^{out}}$

### 图的邻接矩阵

![截屏2023-02-15 下午8.38.59](https://p.ipic.vip/v7fwoe.png)

无向图的邻接矩阵是对称阵；

有向图的邻接矩阵是非对称阵；

当数据量很大的时候，邻接矩阵将非常占内存；

### 图的连接列表

图的连接列表：只记录存在连接的节点对

![截屏2023-02-15 下午8.44.25](https://p.ipic.vip/y4fi7w.png)

### 图的邻接列表

图的邻接列表：只记录每个节点与该节点连接的节点

![截屏2023-02-15 下午8.46.03](https://p.ipic.vip/otcjnu.png)

### 无权图、有权图等

![截屏2023-02-15 下午8.49.46](https://p.ipic.vip/bq7x6m.png)

![截屏2023-02-15 下午9.01.47](https://p.ipic.vip/911t44.png)

### 连通图

任意两个节点都可以触达即为**连通图**；

不能实现任意两个节点触达即为**非连通图**；

有向图中，任意两个节点可以相互触达即为**强连通图**；

在无向图中，任意两个节点可以相互触达即为**弱连通图**；

![截屏2023-02-15 下午9.19.55](https://p.ipic.vip/ntp7zz.png)





## 图的基本表示--节点

传统图机器学习（人工特征工程+机器学习）

### 节点层面的特征工程

#### 半监督节点分类

- 节点的度
- 节点的重要度（邻接矩阵按行/按列求和得到重要度）
- 节点的集聚系数
- 节点周围的子图

#### 节点连接数（度）

![截屏2023-02-16 下午9.41.09](https://p.ipic.vip/s13yvc.png)

#### 重要度分类

##### Eigenvector centrality

特征向量节点重要度（节点相邻节点的重要度）

![截屏2023-02-15 下午9.40.35](https://p.ipic.vip/93ltwm.png)

![截屏2023-02-15 下午9.41.06](https://p.ipic.vip/26didf.png)

特征向量重要度比度重要度更偏向真正重要的节点（连接边很多不一定很重要），可能不收敛；

##### Betweenness centrality

![截屏2023-02-16 下午9.50.19](https://p.ipic.vip/80sutu.png)

##### Closeness centrality

![截屏2023-02-16 下午9.52.33](https://p.ipic.vip/tb0gjm.png)

##### Clustering Coefficient

![截屏2023-02-16 下午9.54.02](https://p.ipic.vip/d6q9so.png)

#### 节点周围的子图

![截屏2023-02-16 下午9.57.42](https://p.ipic.vip/jn9trr.png)

![截屏2023-02-16 下午9.59.12](https://p.ipic.vip/i3jiy9.png)

![截屏2023-02-16 下午9.59.50](https://p.ipic.vip/j9kb5d.png)

![截屏2023-02-16 下午10.01.09](https://p.ipic.vip/7s00df.png)

#### 总结

![截屏2023-02-16 下午10.01.32](https://p.ipic.vip/t3dtxu.png)



### 连接层面的特征工程





### 全图层面的特征工程

**目标：提取出的特征应反映全图结构特点**

#### 子图匹配-Graphlet Kernel

图中的Bag-of-Words(BoW)方法：将每个词出现的频率作为文档的向量；

![截屏2023-02-16 下午8.32.40](https://p.ipic.vip/6aupsq.png)图中的Bag-of-Node-Degrees方法：用每个节点的度作为向量；

![截屏2023-02-16 下午8.31.55](https://p.ipic.vip/nwf61d.png)

统计全图中子图的个数![截屏2023-02-16 下午8.38.29](https://p.ipic.vip/xkqpxl.png)

11个子图是非同形的

![截屏2023-02-16 下午8.34.54](https://p.ipic.vip/6uepgn.png)

![截屏2023-02-16 下午8.51.32](https://p.ipic.vip/oyf0si.png)

![截屏2023-02-16 下午8.41.21](https://p.ipic.vip/kd43k2.png)

![截屏2023-02-16 下午8.53.27](https://p.ipic.vip/emk3er.png)

当两个图的大小不一致，则需要将图进行归一化，$h_G$表示归一化后的结果。

由于子图匹配需要消耗大量时间和算力，所以很少使用这个算法，时间的复杂度$n^k$，其中n是节点个数，k是子图数量。

#### 颜色微调算法-Weisfeiler-Lehman Kernel

![截屏2023-02-16 下午8.58.33](https://p.ipic.vip/jtrmre.png)

![截屏2023-02-16 下午8.58.59](https://p.ipic.vip/h7u46k.png)

![截屏2023-02-16 下午8.59.42](https://p.ipic.vip/x2sfl2.png)

![截屏2023-02-16 下午9.00.15](https://p.ipic.vip/d1v53e.png)

![截屏2023-02-16 下午9.01.06](https://p.ipic.vip/ic3qdc.png)

第一个列表显示错误：应该为[6,2,1,2,1,0,2,1,0,0,2,1,0]

注意：这里的列表是在进行所有的颜色定义的时候，存在对应编码的节点个数，最开始的时候，两张图所有节点都是1，所以两个列表的1对应列表位置的取值为6，依次类推。![截屏2023-02-16 下午9.21.25](https://p.ipic.vip/quhp29.png)

![截屏2023-02-16 下午9.05.24](https://p.ipic.vip/cx181r.png)

方法：将每个节点的颜色hash编码补充到词汇表中，然后统计编码的个数组成向量。

注意：需要统计任意一个图出现的编码才考虑，都没出现不需要考虑。

![截屏2023-02-16 下午9.36.34](https://p.ipic.vip/nhxgma.png)
